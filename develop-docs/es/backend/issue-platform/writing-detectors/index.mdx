---
title: Creación de detectores
sidebar_order: 10
og_image: /og-images/backend-issue-platform-writing-detectors.png
---

Los detectores de incidencias identifican problemas de la aplicación examinando uno o más conjuntos de datos recopilados por Sentry y reportan las incidencias detectadas a través de la <Link to="/backend/issue-platform/">Plataforma de incidencias</Link>. Los detectores deben generar huellas (fingerprints) precisas para las incidencias y proporcionar información práctica para los desarrolladores.

<div id="considerations">
  # Consideraciones
</div>

<div id="fingerprinting">
  ## Huellas
</div>

Los eventos de error se clasifican mediante diversas estrategias, como los stack traces. Los usuarios pueden personalizar estas estrategias. El fingerprinting de errores es un mecanismo complejo y en constante evolución que existe desde hace muchos años.

Para nuevos tipos de incidencias, se recomienda empezar con una estrategia de agrupación sencilla de un solo nivel. Las estrategias de fingerprinting deberían evolucionar gradualmente, ya que un enfoque incremental funciona mejor. Es difícil anticipar todos los casos límite hasta que se pueda aplicar el fingerprinting a datos reales.

Una huella representa un problema único. Cada ocurrencia con esa huella tiene la misma causa raíz y la misma solución. Para incidencias de consultas N+1 en la base de datos, una huella es un hash de la descripción del span db repetido y parametrizado, la descripción del span de origen, la descripción del span padre y una clase de problema (N+1 DB Query). <Link to="https://github.com/getsentry/sentry/blob/master/src/sentry/utils/performance_issues/detectors/n_plus_one_db_span_detector.py#L253-L258">Código</Link>.

Si una incidencia tiene 3 eventos, significa que este problema específico ha ocurrido 3 veces con la misma causa. Corregir esa única incidencia debería evitar que se repitan las 3 instancias.

<div id="risk-loose-grouping-strategy">
  ### Riesgo: estrategia de agrupación laxa
</div>

Supongamos que agrupamos todos los problemas de consultas N+1 en la base de datos basándonos únicamente en la clase del problema. Esto contraviene el principio de “mismo problema, misma solución”. Diferentes consultas N+1 en la base de datos requerirán soluciones distintas.

<div id="risk-strict-grouping-strategy">
  ### Riesgo: estrategia de agrupación estricta
</div>

Supongamos que agrupamos todas las consultas N+1 a la base de datos que tienen exactamente la misma descripción de span de la base de datos (sin parametrización). En este caso, si una consulta contiene campos dinámicos como fechas, se generarían demasiados problemas por separado. Aunque estos problemas tienen la misma solución, no se agruparían. Esto también va en contra de los principios del fingerprinting.

<div id="risk-fingerprinting-only-on-mock-events">
  ### Riesgo: Fingerprinting solo en eventos simulados
</div>

Asegúrate de que la estrategia de fingerprinting se pruebe con datos reales, no solo de Sentry sino también de otras organizaciones.

<div id="example-n1-db-query-fingerprinting-brainstorm">
  ### Ejemplo: lluvia de ideas sobre la identificación de huellas para consultas N+1 en la base de datos
</div>

Pensemos juntos un ejemplo de fingerprinting de consultas N+1 en la base de datos. Aquí va el desglose:

- Problema: Nuestro objetivo es identificar consultas N+1 en la base de datos.
- Información contextual disponible para el análisis:
    - Clase de problema: Identificación de la clase de problema específica de las consultas N+1.
    - Operación y descripción del span repetido: Análisis de la operación y la descripción de los spans repetidos.
    - Span que inició los spans repetidos (span precedente): Examen del span que desencadenó la repetición de spans.
    - Span padre de los spans repetidos y precedentes: Comprensión de la relación y jerarquía entre el span padre y los spans repetidos/precedentes.
    - Nombre de la transacción: Consideración del nombre de la transacción asociado con la consulta, teniendo en cuenta que distintas transacciones pueden presentar el mismo problema N+1.
    - Tags: Exploración de cualquier tag relevante asociado con la consulta.
    - SDKs: Consideración del tipo o la versión de los SDK en la transacción.
- Aspectos únicos relevantes para el problema:
    - Clase de problema: Captura de la clase de problema específica de las consultas N+1.
    - Operación y descripción del span repetido: Identificación de la operación y la descripción del span repetido que caracteriza el problema.
    - Span que inició los spans repetidos (span precedente): Análisis del span responsable de iniciar la repetición de spans.
    - Span padre de los spans repetidos y precedentes: Consideración del span padre que abarca tanto los spans repetidos como los precedentes.
    - Nombre de la transacción: Reconocimiento de que distintas transacciones pueden manifestar el mismo problema N+1.
    - Tags: Consideración de cualquier tag asociado con la consulta.
    - Cualquier campo dinámico: Consideración de la presencia de campos dinámicos en la consulta.
- Creación de la huella resultante:
    - Clase de problema: Inclusión de la clase de problema de las consultas N+1 en la huella.
    - Descripción parametrizada del span repetido: Uso de descripciones parametrizadas del span repetido en la huella.
    - Descripción parametrizada del span de origen: Inclusión de descripciones parametrizadas del span de origen en la huella.
    - Descripción parametrizada del span padre + operación del padre: Inclusión de descripciones parametrizadas del span padre, junto con la operación del padre, en la huella.

Al utilizar este enfoque de fingerprinting, podemos identificar y clasificar eficazmente las consultas N+1 en la base de datos según sus características y contexto, garantizando un agrupamiento efectivo.

<div id="actionabilityusefulness">
  ## Aplicabilidad/Utilidad
</div>

Una vez que hayas comprendido el proceso de fingerprinting y sepas cómo agrupar instancias del mismo problema con la misma solución, el siguiente paso es dar a los usuarios toda la información necesaria para corregirlo. La calidad de un issue no reside solo en su detección precisa, sino también en su aplicabilidad.

La detección de consultas N+1 a la base de datos depende en gran medida del análisis de spans para identificar spans problemáticos y guiar a los usuarios hacia una posible solución.

¡Informar datos circunstanciales no es útil! Esta es una distinción crucial entre issues y alertas. Los issues deben señalar los problemas de raíz y ayudar a resolverlos.
![Captura de árbol de spans](img/issuePlatformFingerprinting01.png)

<div id="signal-vs-noise">
  ## Señal vs. ruido
</div>

Con cada nuevo tipo de issue, podríamos estar añadiendo cada vez más ruido al producto Issues. La fatiga por nuevos issues es real para nuestros clientes. Por eso es importante entender cómo un nuevo detector que quieres lanzar afecta el ruido general del flujo de Issues.

La detección precisa de problemas realmente valiosos y un agrupamiento correcto pueden transformar el “ruido” en “señal”. Todo detector debe evaluarse con este criterio. Existe la opción de [definir una configuración de ruido personalizada](https://develop.sentry.dev/issue-platform/#register-an-issue-type) al crear un nuevo detector.

<div id="development">
  # Desarrollo
</div>

<div id="bitsnbobs">
  ## Varios y demás
</div>

Los problemas de rendimiento afectan a muchas partes del sistema y es fácil pasar algo por alto. Aquí tienes algunos puntos que revisar para asegurarte de que tus incidencias funcionen bien:

- **Bordes de la interfaz**. ¿Tus incidencias se muestran correctamente en el flujo de incidencias? Revisa el nivel de gravedad, el título, la descripción y el contenido de la tarjeta al pasar el cursor.
- **Notificaciones por correo electrónico**. ¿La interfaz coincide con la página de detalles de la incidencia para las incidencias de tu nuevo detector?
- **Notificaciones de Slack**. ¿Tienen sentido las notificaciones de tu incidencia?
- **Integraciones**. ¿Funciona bien convertir tu incidencia en una tarea de Jira/Linear/GitLab?
- **Buscar**. ¿Es posible buscar tu incidencia por tipo en el flujo de incidencias?
- **Insignias Alpha y Beta**. ¿Añadiste las insignias Alpha o Beta a la página de detalles de la incidencia según corresponda?
- **Documentación pública**. ¿Tu detector tiene una página correspondiente en [docs.sentry.io](https://docs.sentry.io)?

<div id="testing">
  ## Pruebas
</div>

Siempre que sea posible, realiza pruebas con datos reales. Se recomienda usar archivos JSON de eventos de transacciones reales para llevar a cabo pruebas unitarias de Performance Detectors.

Otra herramienta que utilizamos para validar y probar cambios en los detectores es un [script de CLI](https://github.com/getsentry/sentry/pull/39727):

```shell
sentry performance detect /ruta/al/event.json
```


<div id="deployment">
  ## Despliegue
</div>

Una estrategia de lanzamiento seguro dependerá de cómo tu equipo implemente la detección y la creación de incidencias. Aun así, hay consideraciones generales que conviene tener en cuenta:

* Ejecutar detectores en modo de prueba (dry run)
  * Validar la precisión de la detección con datos reales
  * Comprobar la detección en el entorno de producción. Un ejemplo de cómo realizar una auditoría está [aquí](https://www.notion.so/How-To-Audit-Performance-Detector-Dry-Runs-5d2c056b55f44e9d8eac1fd1834a4a20).
* Desacoplar la detección y la creación de incidencias
  * Implementar la detección y la creación de incidencias por separado
* Opciones para tasas y umbrales\
  En Sentry usamos dos tipos de opciones: por lo general, “options” se refiere a `options` a nivel de sistema y `projectoptions` a opciones configuradas para proyectos específicos. Usamos una combinación de ambas para permitir lo siguiente:
  * Tasas de detección
    * Hemos implementado tasas de detección independientes, lo que nos permite añadir nuevos detectores o ajustar umbrales en detectores existentes. Esto nos permite rastrear y reportar estos cambios mediante métricas.
  * Umbrales
    * Esta capacidad nos permite ajustar con precisión nuestros detectores y observar sus efectos en tiempo real en el entorno de producción. Al modificar los parámetros y los umbrales de detección, podemos monitorizar cómo impactan estos cambios en la precisión de la detección y en la cantidad de incidencias detectadas.

```python
# projectoptions/defaults.py
key="sentry:performance_issue_creation_rate", default=1.0

key="sentry:performance_issue_settings",
default={
"n_plus_one_db_count": 5,
"n_plus_one_db_duration_threshold": 500,
}
```

![Captura de pantalla de la configuración de opciones del proyecto](img/issuePlatformFingerprinting02.png)

* Configuración de detección por proyecto
  [Configuración del proyecto:](https://sentry.io/settings/sentry/projects/sentry/performance/)

  ![Captura de pantalla de la configuración del proyecto](img/issuePlatformFingerprinting03.png)


<div id="detector-threshold-configurations">
  ## Configuraciones de umbrales del detector
</div>

Una vez que el detector se haya probado y desplegado, puedes agregar la incidencia correspondiente a la lista de configuraciones de umbral del detector en **Project Settings > Performance**:

![Detector Threshold settings customer ui screenshot](img/issuePlatformCustomerDetectorSettings.png)

Asegúrate también de agregar la incidencia correspondiente a la interfaz de configuración de administración. Esto permite que el equipo de soporte habilite o deshabilite la detección de la incidencia para un proyecto:

![Detector Threshold settings admin ui screenshot](img/issuePlatformAdminDetectionSettings.png)

Aspectos a tener en cuenta al hacer configurables los umbrales del detector:

- El **valor máximo del umbral** del rango no debe ser tan alto como para volver la incidencia indetectable. No buscamos desactivar la detección aquí.
- El **valor mínimo del umbral** del rango debe tener relevancia cuando se supere. Queremos que las incidencias que detectamos sean lo suficientemente significativas como para que los usuarios profundicen.
- El **impacto** de cambiar los umbrales configurables **debe ser fácil de interpretar para el usuario**. Por ejemplo, en lugar de configurar la duración en bruto de los spans base de la base de datos en el hilo principal, los usuarios pueden configurar la caída resultante de la tasa de fotogramas.

![Detector Threshold settings db on main thread screenshot](img/issuePlatformDbonMainThreadDetectorSetting.png)