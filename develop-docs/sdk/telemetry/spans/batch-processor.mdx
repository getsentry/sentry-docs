---
title: Batch Processor
---

<Alert level="warning">
  ðŸš§ This document is work in progress.
</Alert>

<Alert>
  This document uses key words such as "MUST", "SHOULD", and "MAY" as defined in [RFC 2119](https://www.ietf.org/rfc/rfc2119.txt) to indicate requirement levels.
</Alert>

The BatchProcessor batches spans and logs into one envelope to reduce the number of HTTP requests. When an SDK implements span streaming or logs, it MUST use a BatchProcessor, which is similar to [OpenTelemetry's Batch Processor](https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/batchprocessor/README.md). The BatchProcessor holds logs and finished spans in memory and batches them together into envelopes. It uses a combination of time and size-based batching. When writing this, the BatchProcessor only handles spans and logs, but an SDK MAY use it for other telemetry data in the future.

## Specification

Whenever the SDK finishes a span or captures a log, it MUST put it into the BatchProcessor. The SDK MUST NOT put unfinished spans into the BatchProcessor.

The BatchProcessor MUST start a timeout of 5 seconds when the SDK adds the first span or log. When the timeout exceeds, the BatchProcessor MUST send all spans or logs, no matter how many items it contains. The SDK MAY choose a different value for the timeout, but it MUST NOT exceed 30 seconds, as this can lead to problems with the span buffer on the backend, which uses a time interval of 60 seconds for determining segments for spans. The BatchProcessor MUST only start a new timeout, when it has spans or logs to send, to avoid running the timeout unnecessarily.

The BatchProcessor MUST send all items after the SDK when containing spans or logs exceeding 1MiB in size. The SDK MAY choose a different value for the max batch size keeping the [envelope max sizes](/sdk/data-model/envelopes/#size-limits) in mind. The SDK MUST calculate the size of a span or a log to manage the BatchProcessor's memory footprint. The SDK MUST serialize the span or log and calculate the size based on the serialized JSON bytes. As serialization is expensive, the BatchProcessor SHOULD keep track of the serialized spans and logs and pass these to the envelope to avoid serializing multiple times.

When the BatchProcessor sends all spans or logs, it MUST reset its timeout and remove all spans and logs. The SDK MUST apply filtering and sampling before adding spans or logs to the BatchProcessor. The SDK MUST apply rate limits to spans and logs after they leave the BatchProcessor to send as much data as possible by dropping data as late as possible.

The BatchProcessor MUST send all spans and logs in memory to avoid data loss in the following scenarios:

1. When the user calls `SentrySDK.flush()`, the BatchProcessor MUST send all data in memory.
2. When the user calls  `SentrySDK.close()`, the BatchProcessor MUST send all data in memory.
3. When the application shuts down gracefully, the BatchProcessor SHOULD send all data in memory. This is mostly relevant for mobile SDKs already subscribed to these hooks, such as [applicationWillTerminate](https://developer.apple.com/documentation/uikit/uiapplicationdelegate/applicationwillterminate(_:)) on iOS.
4. When the application moves to the background, the BatchProcessor SHOULD send all data in memory and stop the timer. This is mostly relevant for mobile SDKs.
5. We're working on concept for crashes, and will update the specification when we have more details.

The detailed specification is written in the [Gherkin syntax](https://cucumber.io/docs/gherkin/reference/). The specification uses spans as an example, but the same applies to logs or any other future telemetry data.


```Gherkin
Scenario: No spans in BatchProcessor 1 span added
    Given no spans in the BatchProcessor
    When the SDK finishes 1 span
    Then the SDK puts this span to the BatchProcessor
    And starts a timeout of 5 seconds
    And doesn't send the span to Sentry

Scenario: Span added before timeout exceeds
    Given span A in the BatchProcessor
    Given 4.9 seconds pass
    When the SDK finishes span B
    Then the SDK adds span B to the BatchProcessor
    And doesn't reset the timeout
    And doesn't send the spans A and B in the BatchProcessor to Sentry

Scenario: Timeout exceeds and no spans or logs to send
    Given no spans in the BatchProcessor
    When the timeout exceeds
    Then the BatchProcessor does nothing
    And doesn't start a new timeout

Scenario: Spans with size of 1 MiB - 1 byte added, timeout exceeds
    Given spans with size of 1 MiB - 1 byte in the BatchProcessor
    When the timeout exceeds
    Then the SDK adds all the spans to one envelope
    And sends them to Sentry
    And resets the timeout
    And clears the BatchProcessor

Scenario: Spans with size of 1 MiB - 1 byte added within 4.9 seconds
    Given spans with size of 1 MiB - 1 byte in the BatchProcessor
    When the SDK finishes another span and puts it into the BatchProcessor
    Then the BatchProcessor puts all spans into one envelope
    And sends the envelope to Sentry
    And resets the timeout
    And clears the BatchProcessor

Scenario: Unfinished spans
    Given no span is in the BatchProcessor
    When the SDK starts a span but doesn't finish it
    Then the BatchProcessor is empty

Scenario: Span filtered out
    Given no span is in the BatchProcessor
    When the finishes a span
    And the span is filtered out
    Then the BatchProcessor is empty

Scenario: Span not sampled
    Given no span is in the BatchProcessor
    When the finishes a span
    And the span is not sampled
    Then the BatchProcessor is empty

Scenario: 1 span added application crashes
  Given 1 span in the SpansAggregator
  When the SDK detects a crash
  Then the SDK does nothing with the items in the BatchProcessor
  And loses the spans in the BatchProcessor

```

## Sudden Process Terminations

When the BatchProcessor handles logs, it MUST minimize the loss of logs, so developers can fully trust logs. In that case, the BatchProcessor MUST prevent data loss for sudden process terminations, such as crashes or watchdog terminations.

Since each environment is unique, SDKs have three options to choose from. The options become more complex as their number increases. The first option is the simplest, and the last option is the most complicated. SDKs SHOULD implement the least complex option that is suitable for their environment.

### 1. Store Data into Envelope

When the SDK detects a sudden process termination it MUST put all items in the BatchProcessor into one envelope and store it to disk. When the SDK starts again, it MUST send this envelope to Sentry. The BatchProcessor MUST keep it's existing logic described in the specification above.

If SDKs can't reliably detect sudden process terminations or they can't reliably store envelopes to disk when a sudden process termination happens, they SHOULD implement the [FileStream Cache](#2-file-stream-cache) or the [FIFO Queue with Async FileStream Cache](#3-fifo-queue-with-async-file-stream-cache), but it's also acceptable to start with this option as a best effort before adding one of the more complex options

### 2. FileStream Cache

SDKs for which blocking the main thread is a nogo, such as Android and Apple, SDKs MUST NOT implement this option. They SHOULD implement the [FIFO Queue with Async FileStream Cache](#3-fifo-queue-with-async-file-stream-cache).

Instead of keeping the data in memory, the BatchProcessor stores the data on the calling thread to disk. The BatchProcessor keeps the timeout logic to ensure the delay of sending data to Sentry is minimal. For efficiency, the BatchProcessor SHOULD use file handles or file streams when writing data to disk.

The BatchProcessor uses two types of cache files:
- **`current`** - The file the processor is actively writing to
- **`sending`** - The file being converted to an envelope and sent to Sentry

When the timeout expires or the cache file hits the size limit, the BatchProcessor renames the `current` file to `sending`, creates a new `current` file for incoming data, converts the data in the `sending` file to an envelope, sends it to Sentry, and then deletes the `sending` file. When the SDK starts again, it MUST check if there are any cache files in the cache directory (both `current` and `sending`) and if so, it MUST load the data from the files and send it to Sentry.


### 3. FIFO Queue with Async FileStream Cache

This is the recommended option for SDKs that can't reliably detect sudden process terminations or they can't reliably store envelopes to disk when a sudden process termination happens, such as Android and Apple.

With this option, the BatchProcessor stores its logs in a thread-safe FIFO queue, residing in an async-safe memory space, allowing the crash reporter to write them to disk when a crash occurs. Furthermore, the BatchProcessor stores logs asynchronously into a file, allowing it to recover after an abnormal termination, for which the crash handler can't run. The BatchProcessor MUST store the logs immediately to disk after adding them to the FIFO queue.

When the BatchProcessor receives a log, it performs the following steps

1. Put the log into the FIFO queue on the calling thread.
2. On a background thread, serialize the next log of the FIFO queue and store it in the batch-processor-cache-file.
3. Remove the log from the FIFO queue.
4. If the queue isn't empty, go back to step 2.

The FIFO queue has a `max-logs-count` of 64 logs. When the FIFO queue exceeds `max-logs-count` log items, the BatchProcessor MUST drop logs and record client reports with the category `queue_overflow` for every dropped log. SDKs MAY choose a different `max-logs-count` value, if needed. SDKs MUST NOT expose the `max-logs-count` value to users as an option. We can make this option public in the future, if required.

When SDKs detect an abnormal process termination, they MUST write the logs in the FIFO queue to the `batch-processor-recovery-file` and send these logs on the next SDK launch. To avoid sending duplicated logs, the SDKs MUST deduplicate the logs from the `batch-processor-recovery-file` and `batch-processor-cache-file` based on the logID after an abnormal process termination before sending them.

The BatchProcessor MUST keep two `batch-processor-cache-files`. When it sends the logs from `batch-processor-cache-file`, it renames it to `batch-processor-cache-file-to-flush` and creates a new `batch-processor-cache-file` to avoid losing logs if an abnormal termination occurs when flushing the logs. To avoid sending duplicate logs if an abnormal termination occurs in between storing the envelope and deleting the cache file, the BatchProcessor MUST first store the envelope to the same folder as the BatchProcessor files. After deleting the `batch-processor-cache-file-to-flush`, SDKs MUST move the envelope to the envelope cache folder. As moving files is usually atomic, SDKs avoid sending duplicated logs in the described scenario. These are the flushing steps:

1. Rename `batch-processor-cache-file` to `batch-processor-cache-file-to-flush`.
2. Create a new `batch-processor-cache-file` and store new logs to this file.
3. Convert the logs in `batch-processor-cache-file-to-flush` to an envelope and name it `batch-processor-cache-envelope-to-flush`. SDKs MUST not put the envelope into the envelope cache folder yet. Instead, they MUST store the envelope to the same folder as the other BatchProcessor files.
4. Delete the file `batch-processor-cache-file-to-flush`
5. Move the `batch-processor-cache-envelope-to-flush` to the envelopes cache folder.


The detailed specification is written in the [Gherkin syntax](https://cucumber.io/docs/gherkin/reference/). The specification uses logs as an example, but the same applies to logs or any other future telemetry data.

SDK detects abnormal process termination scenarios:

```Gherkin
Scenario: One log in FIFO queue
    Given one log in the FIFO queue
    And no logs in the `batch-processor-cache-file`
    When the SDK detects an abnormal process termination
    Then the SDK puts this log to the `batch-processor-recovery-file`

Scenario: Log in FIFO queue and cache file
    Given one log in the FIFO queue
    And one log in the `batch-processor-cache-file`
    When the SDK detects an abnormal process termination
    Then the SDK puts this log to the `batch-processor-recovery-file`
```

SDK doesn't detect abnormal process termination scenarios:

```Gherkin
Scenario: One log in FIFO queue
    Given one log in the FIFO queue
    And no logs in the `batch-processor-cache-file`
    When the process terminates abnormally and the SDK can't detect it
    Then the SDK loses this log in the FIFO queue

Scenario: Log in FIFO queue and cache file
    Given one log in the FIFO queue
    And one log in the `batch-processor-cache-file`
    When the process terminates abnormally and the SDK can't detect it
    Then the SDK loses this log in the FIFO queue
    But it doesn't lose the log in the `batch-processor-cache-file`
```

SDK Launch Scenarios

`x` is the index of the batch-processor-recovery-file and batch-processor-cache-file

```Gherkin
Scenario: SDK Launch after abnormal termination
    Given one log in the `batch-processor-recovery-file-x`
    And one log in the `batch-processor-cache-file-x`
    When the SDK starts
    Then the SDK deduplicates the logs from the `batch-processor-recovery-file-x` and `batch-processor-cache-file-x` based on the logID
    And puts the logs into one envelope named `batch-processor-envelope-x` in the BatchProcessor directory
    And deletes the `batch-processor-recovery-file-x` and `batch-processor-cache-file-x`
    And moves the logs envelope `batch-processor-envelope-x` from the BatchProcessor directory to the envelopes cache folder

Scenario: Abnormal termination before deleting recover and crash file
    Given the SDK stored the envelope `batch-processor-envelope-0` to the BatchProcessor directory
    But it didn't delete the `batch-processor-recovery-file-0` and `batch-processor-cache-file-0`
    When the SDK starts
    Then the SDK deletes the `batch-processor-recovery-file-0` and `batch-processor-cache-file-0`
    And moves the logs envelope from the BatchProcessor directory to the envelopes cache folder
```


The BatchProcessor maintains its logic of batching multiple logs together into a single envelope to avoid multiple HTTP requests.

Hybrid SDKs pass every log down to the native SDKs, which will put every log in their BatchProcessor and its cache when logs are ready for sending, meaning after they go through beforeLog, integrations, processors, etc.
