---
title: Batch Processor
---

<Alert level="warning">
  ðŸš§ This document is work in progress.
</Alert>

<Alert>
  This document uses key words such as "MUST", "SHOULD", and "MAY" as defined in [RFC 2119](https://www.ietf.org/rfc/rfc2119.txt) to indicate requirement levels.
</Alert>

The BatchProcessor batches spans and logs into one envelope to reduce the number of HTTP requests. When an SDK implements span streaming or logs, it MUST use a BatchProcessor, which is similar to [OpenTelemetry's Batch Processor](https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/batchprocessor/README.md). The BatchProcessor holds logs and finished spans in memory and batches them together into envelopes. It uses a combination of time and size-based batching. When writing this, the BatchProcessor only handles spans and logs, but an SDK MAY use it for other telemetry data in the future.

## Specification

Whenever the SDK finishes a span or captures a log, it MUST put it into the BatchProcessor. The SDK MUST NOT put unfinished spans into the BatchProcessor.

The BatchProcessor MUST start a timeout of 5 seconds when the SDK adds the first span or log. When the timeout exceeds, the BatchProcessor MUST send all spans or logs, no matter how many items it contains. The SDK MAY choose a different value for the timeout, but it MUST NOT exceed 30 seconds, as this can lead to problems with the span buffer on the backend, which uses a time interval of 60 seconds for determining segments for spans. The BatchProcessor MUST only start a new timeout, when it has spans or logs to send, to avoid running the timeout unnecessarily.

The BatchProcessor MUST send all items after the SDK when containing spans or logs exceeding 1MiB in size. The SDK MAY choose a different value for the max batch size keeping the [envelope max sizes](/sdk/data-model/envelopes/#size-limits) in mind. The SDK MUST calculate the size of a span or a log to manage the BatchProcessor's memory footprint. The SDK MUST serialize the span or log and calculate the size based on the serialized JSON bytes. As serialization is expensive, the BatchProcessor SHOULD keep track of the serialized spans and logs and pass these to the envelope to avoid serializing multiple times.

When the BatchProcessor sends all spans or logs, it MUST reset its timeout and remove all spans and logs. The SDK MUST apply filtering and sampling before adding spans or logs to the BatchProcessor. The SDK MUST apply rate limits to spans and logs after they leave the BatchProcessor to send as much data as possible by dropping data as late as possible.

The BatchProcessor MUST send all spans and logs in memory to avoid data loss in the following scenarios:

1. When the user calls `SentrySDK.flush()`, the BatchProcessor MUST send all data in memory.
2. When the user calls  `SentrySDK.close()`, the BatchProcessor MUST send all data in memory.
3. When the application shuts down gracefully, the BatchProcessor SHOULD send all data in memory. This is mostly relevant for mobile SDKs already subscribed to these hooks, such as [applicationWillTerminate](https://developer.apple.com/documentation/uikit/uiapplicationdelegate/applicationwillterminate(_:)) on iOS.
4. When the application moves to the background, the BatchProcessor SHOULD send all data in memory and stop the timer. This is mostly relevant for mobile SDKs.
5. We're working on concept for crashes, and will update the specification when we have more details.

The detailed specification is written in the [Gherkin syntax](https://cucumber.io/docs/gherkin/reference/). The specification uses spans as an example, but the same applies to logs or any other future telemetry data.


```Gherkin
Scenario: No spans in BatchProcessor 1 span added
    Given no spans in the BatchProcessor
    When the SDK finishes 1 span
    Then the SDK puts this span to the BatchProcessor
    And starts a timeout of 5 seconds
    And doesn't send the span to Sentry

Scenario: Span added before timeout exceeds
    Given span A in the BatchProcessor
    Given 4.9 seconds pass
    When the SDK finishes span B
    Then the SDK adds span B to the BatchProcessor
    And doesn't reset the timeout
    And doesn't send the spans A and B in the BatchProcessor to Sentry

Scenario: Timeout exceeds and no spans or logs to send
    Given no spans in the BatchProcessor
    When the timeout exceeds
    Then the BatchProcessor does nothing
    And doesn't start a new timeout

Scenario: Spans with size of 1 MiB - 1 byte added, timeout exceeds
    Given spans with size of 1 MiB - 1 byte in the BatchProcessor
    When the timeout exceeds
    Then the SDK adds all the spans to one envelope
    And sends them to Sentry
    And resets the timeout
    And clears the BatchProcessor

Scenario: Spans with size of 1 MiB - 1 byte added within 4.9 seconds
    Given spans with size of 1 MiB - 1 byte in the BatchProcessor
    When the SDK finishes another span and puts it into the BatchProcessor
    Then the BatchProcessor puts all spans into one envelope
    And sends the envelope to Sentry
    And resets the timeout
    And clears the BatchProcessor

Scenario: Unfinished spans
    Given no span is in the BatchProcessor
    When the SDK starts a span but doesn't finish it
    Then the BatchProcessor is empty

Scenario: Span filtered out
    Given no span is in the BatchProcessor
    When the finishes a span
    And the span is filtered out
    Then the BatchProcessor is empty

Scenario: Span not sampled
    Given no span is in the BatchProcessor
    When the finishes a span
    And the span is not sampled
    Then the BatchProcessor is empty

Scenario: 1 span added application crashes
  Given 1 span in the SpansAggregator
  When the SDK detects a crash
  Then the SDK does nothing with the items in the BatchProcessor
  And loses the spans in the BatchProcessor

```

## Sudden Process Terminations

The BatchProcessor MUST minimize the loss of logs for sudden process terminations, such as crashes or watchdog terminations.

Each SDK environment is unique. Therefore, SDKs have three options to choose from to minimize data loss. As their number increases, the options get more complex. The first option is the simplest, and the last option is the most complicated. SDKs SHOULD implement the least complex option that is suitable for their environment.

### 1. Flush All Data

When the SDK detects a sudden process termination, it MUST put all items in the BatchProcessor into one envelope and flush it. If your SDK has an offline cache, it MAY flush the envelope to disk and skip sending it to Sentry, if it ensures to send the envelope the next time the SDK starts. The BatchProcessor MUST keep its existing logic described in the [specification](#specification) above.

Suppose your SDK can't reliably detect sudden process terminations, or it can't reliably flush envelopes to Sentry or disk when a sudden process termination happens. In that case, it SHOULD implement the [FileStream Cache](#2-file-stream-cache) or the [FIFO Queue with Async FileStream Cache](#3-fifo-queue-with-async-file-stream-cache). It's acceptable to start with this option as a best effort interim solution before adding one of the more complex options.

### 2. FileStream Cache

SDKs for which blocking the main thread is a nogo, such as Android and Apple, SDKs MUST NOT implement this option. They SHOULD implement the [FIFO Queue with Async FileStream Cache](#3-fifo-queue-with-async-file-stream-cache).

With this option, the BatchProcessor stores the data on the calling thread directly to disk. The SDK SHOULD store the BatchProcessor files in a folder that is a sibling of the `envelopes` or `replay` folder, named `batch-processor`. This folder is scoped per DSN, so SDKs ensure not mixing up data for different DSNs. In the `batch-processor` folder, the SDK MUST store two types of cache files:

- **`cache`** - The file the processor is actively writing to
- **`flushing`** - The file being converted to an envelope and sent to Sentry

When the timeout expires or the cache file hits the size limit, the BatchProcessor renames the `cache` file to `flushing`, creates a new `cache` file for incoming data, converts the data in the `flushing` file to an envelope, sends it to Sentry, and then deletes the `flushing` file. When the SDK starts again, it MUST check if there are any cache files in the cache directory (both `cache` and `flushing`) and if so, it MUST load the data from the files and send it to Sentry.


### 3. FIFO Queue with Async FileStream Cache

This is the recommended option for SDKs that can't reliably detect sudden process terminations or that can't reliably store envelopes to disk when a sudden process termination happens, such as Android and Apple. SDKs SHOULD prefer implementing option 1 or 2 if possible, as this option is more complex.

With this option, the BatchProcessor stores its logs in a thread-safe FIFO queue, residing in an async-safe memory space, allowing the crash reporter to write them to disk when a crash occurs. Furthermore, the BatchProcessor stores logs asynchronously into a file, allowing it to recover after an abnormal termination, for which the crash handler can't run. The BatchProcessor MUST store the logs immediately to disk after adding them to the FIFO queue.

The BatchProcessor maintains its logic of batching multiple logs together into a single envelope to avoid multiple HTTP requests.

Hybrid SDKs pass every log down to the native SDKs, which will put every log in their BatchProcessor and its cache when logs are ready for sending, meaning after they go through beforeLog, integrations, processors, etc.

#### Receiving Data

When the BatchProcessor receives a log, it performs the following steps

1. Put the log into the FIFO queue on the calling thread.
2. On a background thread, serialize the next log of the FIFO queue and store it in the `cache` file.
3. Remove the log from the FIFO queue.
4. If the queue isn't empty, go back to step 2.

The FIFO queue has a `max-logs-count` of 64 logs. When the FIFO queue exceeds `max-logs-count` log items, the BatchProcessor MUST drop logs and record client reports with the category `queue_overflow` for every dropped log. SDKs MAY choose a different `max-logs-count` value, if needed. SDKs MUST NOT expose the `max-logs-count` value to users as an option. We can make this option public in the future, if required.

#### Abnormal Process Termination

When SDKs detect an abnormal process termination, they MUST write the logs in the FIFO queue to the `abnormal-termination-x` file where `x` is the an increasing index of the file starting from 0.

When the process terminates abnormally and the SDKs can't detect it, the SDKs lose data in the FIFO queue, which we accept over blocking the calling thread that could be the main thread.

No matter the abnormal process termination, SDKs MUST send data both in the `abnormal-termination-x` and `cache` files on the next SDK start. Please refer to the [SDK start](#sdk-start) section for the detailed specification.

#### Cache File Location

The SDK SHOULD store the BatchProcessor cache files in a folder that is a sibling of the `envelopes` or `replay` folder, named `batch-processor`. This folder is scoped per DSN, so SDKs ensure not mixing up data for different DSNs. The `batch-processor` folder MAY contain the follow files, where `x` is the an increasing index of the file starting from 0:

- `cache` - The active writing cache file for the BatchProcessor
- `cache-to-flush-x` - The file that the BatchProcessor is converting to an envelope.
- `abnormal-termination-x` - The file containing the data from the FIFO queue when an abnormal process termination occurs.
- `envelope-to-flush-x` - The envelope that the BatchProcessor is about to move to the envelopes cache folder, so the SDK can send it to Sentry.

#### Flushing

The BatchProcessor MUST keep two cache files. When the BatchProcessor sends the data from `cache`, it renames it to `cache-to-flush-x` where `x` is the an increasing index of the cache file starting from 0 and creates a new `cache` to avoid losing logs if an abnormal termination occurs when flushing the logs. To avoid sending duplicate logs if an abnormal termination occurs between storing the envelope and deleting the cache file, the BatchProcessor MUST first store the envelope to the same folder as the BatchProcessor files. After deleting the `cache-to-flush-x`, SDKs MUST move the envelope to the envelope cache folder. As moving files is usually atomic, SDKs avoid sending duplicated logs in the described scenario. These are the flushing steps:

1. Rename `cache` to `cache-to-flush-x` where `x` is the an increasing index of the cache file starting from 0.
2. Create a new `cache` and store new logs to this file.
3. Convert the logs in `cache-to-flush-x` to an envelope and name it `envelope-to-flush-x`. SDKs MUST not put the envelope into the envelope cache folder yet. Instead, they MUST store the envelope to the same folder as the other BatchProcessor files.
4. Delete the file `cache-to-flush-x`
5. Move the `envelope-to-flush-x` to the envelopes cache folder.

The detailed specification is written in the [Gherkin syntax](https://cucumber.io/docs/gherkin/reference/). The specification uses logs as an example, but the same applies to logs or any other future telemetry data.

#### SDK start

Whenever the SDK starts, it must check if there is any data in the batch processor folder that needs to be recovered. SDKs MUST perform the following steps when starting:

1. If there is data in the `cache` file, rename the `cache` file to `cache-recovery-to-flush-x`.
2. If there is an `abnormal-termination-x` file, deduplicate data from both the `cache-recovery-to-flush-x` and `abnormal-termination-x` file based on the ID.
3. Put the deduplicated data into the `envelope-to-flush-x` in the batch processor cache folder.
4. Delete the `cache-recovery-to-flush-x` and `abnormal-termination-x` files.
5. Move the `envelope-to-flush-x` to the envelopes cache folder.

As abnormal terminations can occur at any time, there may be multiple `cache-recovery-to-flush-x`, `abnormal-termination-x` or `envelope-to-flush-x` files. SDKs MUST handle multiple file pairs at each of the above-described steps. For example, if there are two pairs of `cache-recovery-to-flush-x` and `abnormal-termination-x`, the SDKs should perform steps 2 to 5 for both pairs.

#### SDK Closes

Whenever the users closes the SDK, the BatchProcessor MUST perform the steps described in the [Flushing](#flushing) section.
