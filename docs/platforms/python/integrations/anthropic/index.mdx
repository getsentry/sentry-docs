---
title: Anthropic
description: "Learn about using Sentry for Anthropic."
---

<Alert level="info" title="Beta">

The support for **Anthropic** is in its beta phase.

We are working on supporting different AI libraries (see [GitHub discussion](https://github.com/getsentry/sentry-python/discussions/3007)).

If you want to try the beta features and are willing to give feedback, please let us know on [Discord](https://discord.com/invite/Ww9hbqr).

</Alert>


This integration connects Sentry with the [Anthropic Python SDK](https://github.com/anthropics/anthropic-sdk-python) and works with Anthropic versions `0.16.0` and above.

## Install

Install `sentry-sdk` from PyPI with the `anthropic` extra:

```bash
pip install --upgrade 'sentry-sdk[anthropic]'
```

## Configure

Add `AnthropicIntegration()` to your `integrations` in the `sentry_sdk.init` call:

```python
from anthropic import Anthropic

import sentry_sdk

sentry_sdk.init(
    dsn="___PUBLIC_DSN___",
    enable_tracing=True,
    traces_sample_rate=1.0,
    integrations=[AnthropicIntegration()],
)

client = Anthropic()
```

## Verify

Verify that the integration works by adding in a bug (such as a bad API key) to your code. This will cause a new error event to be sent to Sentry:

```python
from anthropic import Anthropic
import sentry_sdk

sentry_sdk.init(...)  # same as above

client = Anthropic(api_key="invalid-key")
with sentry_sdk.start_transaction(op="ai-inference", name="AI inference"):
    response = (
        client.messages.create(
            max_tokens=42,
            model="some-model",
            messages=[{"role": "system", "content": "Hello, Anthropic!"}]
        )
    )
    print(response)
```

Executing this script initiates a transaction, which will show up in the Performance section of [sentry.io](https://sentry.io). Furthermore, it also sends Sentry an error event (about the bad API key), which will be linked to the transaction.

It takes a couple of moments for the data to appear in [sentry.io](https://sentry.io).

## Behavior

- The supported modules are currently `chat.messages.create` with `stream=True` and `stream=False`.

- All exceptions leading to an `AnthropicError` are reported.

- Sentry is configured not to consider LLM and tokenizer inputs/outputs as PII. If you want to include them, set `send_default_pii=True` in the `sentry_sdk.init()` call. To explicitly exclude prompts despite `send_default_pii=True`, configure the integration with `include_prompts=False`, as shown in [Options](#options).

## Options

The `AnthropicIntegration` takes an optional `include_prompts` parameter. If set to `False`, prompts are excluded from being sent to Sentry, despite `send_default_pii=True`.

```python
import sentry_sdk
from sentry_sdk.integrations.anthropic import AnthropicIntegration

sentry_sdk.init(
    dsn="___PUBLIC_DSN___",
    enable_tracing=True,
    send_default_pii=True,
    traces_sample_rate=1.0,
    integrations=[
        AnthropicIntegration(
            include_prompts=False, # Exclude prompts from being sent to Sentry, despite send_default_pii=True
        ),
    ],
)
```

## Supported Versions

- Anthropic: 0.16.0+
- Python: 3.7+
