---
title: OpenAI
description: "Adds instrumentation for OpenAI API."
supported:
  - javascript.node
  - javascript.aws-lambda
  - javascript.azure-functions
  - javascript.connect
  - javascript.express
  - javascript.fastify
  - javascript.gcp-functions
  - javascript.hapi
  - javascript.hono
  - javascript.koa
  - javascript.nestjs
  - javascript.electron
  - javascript.nextjs
  - javascript.nuxt
  - javascript.solidstart
  - javascript.sveltekit
  - javascript.react-router
  - javascript.remix
  - javascript.astro
  - javascript.bun
  - javascript.tanstackstart-react
  - javascript.cloudflare
  - javascript
  - javascript.react
  - javascript.angular
  - javascript.vue
  - javascript.svelte
  - javascript.solid
  - javascript.ember
  - javascript.gatsby
---

<PlatformSection notSupported={["javascript", "javascript.react", "javascript.angular", "javascript.vue", "javascript.svelte", "javascript.solid", "javascript.ember", "javascript.gatsby"]}>

## Server-Side Usage

_Import name: `Sentry.openAIIntegration`_

The `openAIIntegration` adds instrumentation for the `openai` API to capture spans by wrapping OpenAI client calls and recording LLM interactions.

<Alert>

This integration is **enabled by default for Node.js-based platforms** and automatically captures spans for OpenAI API method calls. It requires SDK version `10.2.0` or higher.

</Alert>

To customize what data is captured (such as inputs and outputs), see the [Options](#options) in the Configuration section.

</PlatformSection>

<PlatformSection supported={["javascript", "javascript.react", "javascript.angular", "javascript.vue", "javascript.svelte", "javascript.solid", "javascript.ember", "javascript.gatsby", "javascript.nextjs", "javascript.nuxt", "javascript.solidstart", "javascript.sveltekit", "javascript.react-router", "javascript.remix", "javascript.astro", "javascript.tanstackstart-react", "javascript.electron", "javascript.cloudflare"]}>

## Browser-Side Usage

_Import name: `Sentry.instrumentOpenAiClient`_

<PlatformSection supported={["javascript.cloudflare"]}>

<Alert>

For Cloudflare Workers, manual instrumentation is required using `instrumentOpenAiClient`.

</Alert>

</PlatformSection>

<PlatformSection supported={["javascript.nextjs"]}>

<Alert>

For Next.js applications using the Edge runtime, manual instrumentation is required using `instrumentOpenAiClient`. This integration is automatically instrumented in the Node.js runtime.

</Alert>

</PlatformSection>

The `instrumentOpenAiClient` helper adds instrumentation for the `openai` API to capture spans by wrapping OpenAI client calls and recording LLM interactions with configurable input/output recording. You need to manually wrap your OpenAI client instance with this helper. See example below:

```javascript
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.API_KEY, // Warning: API key will be exposed in browser!
});

const client = Sentry.instrumentOpenAiClient(openai, {
  recordInputs: true,
  recordOutputs: true,
});

// Use the wrapped client instead of the original openai instance
const response = await client.chat.completions.create({
  model: "gpt-4o",
  messages: [{ role: "user", content: "Hello!" }],
});
```

To customize what data is captured (such as inputs and outputs), see the [Options](#options) in the Configuration section.

</PlatformSection>

## Configuration

### Options

The following options control what data is captured from OpenAI API calls:

#### `recordInputs`

_Type: `boolean` (optional)_

Records inputs to OpenAI API method calls (such as prompts and messages).

Defaults to `true` if `sendDefaultPii` is `true`.

#### `recordOutputs`

_Type: `boolean` (optional)_

Records outputs from OpenAI API method calls (such as generated text and responses).

Defaults to `true` if `sendDefaultPii` is `true`.

**Usage**

<PlatformSection notSupported={["javascript", "javascript.react", "javascript.angular", "javascript.vue", "javascript.svelte", "javascript.solid", "javascript.ember", "javascript.gatsby"]}>

Automatic Instrumentation

```javascript
Sentry.init({
  dsn: "____PUBLIC_DSN____",
  tracesSampleRate: 1.0, // Required for AI observability
  integrations: [
    Sentry.openAIIntegration({
      // your options here
    }),
  ],
});
```

</PlatformSection>

<PlatformSection supported={["javascript", "javascript.react", "javascript.angular", "javascript.vue", "javascript.svelte", "javascript.solid", "javascript.ember", "javascript.gatsby", "javascript.nextjs", "javascript.nuxt", "javascript.solidstart", "javascript.sveltekit", "javascript.react-router", "javascript.remix", "javascript.astro", "javascript.tanstackstart-react", "javascript.electron", "javascript.cloudflare"]}>

Manual Instrumentation

```javascript
const client = Sentry.instrumentOpenAiClient(openai, {
  // your options here
});
```

</PlatformSection>

## Supported Operations

By default, tracing support is added to the following OpenAI API method calls:

- `chat.completions.create()` - Chat completion requests
- `responses.create()` - Response API requests

Streaming and non-streaming requests are automatically detected and handled appropriately.

## Supported Versions

- `openai`: `>=4.0.0 <7`
