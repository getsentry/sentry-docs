---
title: Vercel AI
description: "Adds instrumentation for Vercel AI SDK."
supported:
  - javascript.node
  - javascript.aws-lambda
  - javascript.azure-functions
  - javascript.connect
  - javascript.express
  - javascript.fastify
  - javascript.gcp-functions
  - javascript.hapi
  - javascript.hono
  - javascript.koa
  - javascript.nestjs
  - javascript.electron
  - javascript.nextjs
  - javascript.nuxt
  - javascript.solidstart
  - javascript.sveltekit
  - javascript.react-router
  - javascript.remix
  - javascript.astro
  - javascript.bun
  - javascript.tanstackstart-react
---

<Alert>

This integration only works in the Node.js and Bun runtimes. Requires SDK version `9.30.0` or higher.

</Alert>

<Alert level="info">

For Next.js applications, the Vercel AI integration can only be added to `sentry.server.config.ts` (server-side configuration). It is not supported in edge configurations (`sentry.edge.config.ts`) or browser configurations (`instrumentation-client.ts`).

</Alert>

_Import name: `Sentry.vercelAIIntegration`_

The `vercelAIIntegration` adds instrumentation for the [`ai`](https://www.npmjs.com/package/ai) SDK by Vercel to capture spans using the [`AI SDK's built-in Telemetry`](https://sdk.vercel.ai/docs/ai-sdk-core/telemetry). Get started with the following snippet:

```javascript
Sentry.init({
  tracesSampleRate: 1.0,
  integrations: [
    Sentry.vercelAIIntegration({
      recordInputs: true,
      recordOutputs: true,
    }),
  ],
});
```

To correctly capture spans, pass the `experimental_telemetry` object with `isEnabled: true` to every `generateText`, `generateObject`, and `streamText` function call. For more details, see the [AI SDK Telemetry Metadata docs](https://sdk.vercel.ai/docs/ai-sdk-core/telemetry#telemetry-metadata).

```javascript
const result = await generateText({
  model: openai("gpt-4o"),
  experimental_telemetry: {
    isEnabled: true,
  },
});
```

## Options

### `force`

Requires SDK version `9.29.0` or higher.

_Type: `boolean`_

Forces the integration to be active, even when the `ai` module is not detected or available. This is useful when you want to ensure the integration is always enabled regardless of module detection.

Defaults to `false`.

```javascript
Sentry.init({
  integrations: [Sentry.vercelAIIntegration({ force: true })],
});
```

### `recordInputs`

Requires SDK version `9.27.0` or higher.

_Type: `boolean`_

Records inputs to the `ai` function call.

Defaults to `true` if `sendDefaultPii` is `true` or if you explicitly set `experimental_telemetry.isEnabled` to `true` in your `ai` function callsites.

```javascript
Sentry.init({
  integrations: [Sentry.vercelAIIntegration({ recordInputs: true })],
});
```

### `recordOutputs`

Requires SDK version `9.27.0` or higher.

_Type: `boolean`_

Records outputs to the `ai` function call.

Defaults to `true` if `sendDefaultPii` is `true` or if you explicitly set `experimental_telemetry.isEnabled` to `true` in your `ai` function callsites.

```javascript
Sentry.init({
  integrations: [Sentry.vercelAIIntegration({ recordOutputs: true })],
});
```

## Identifying functions

In order to make it easier to correlate captured spans with the function calls we recommend setting `functionId` in `experimental_telemetry` in all generation function calls:

```javascript
const result = await generateText({
  model: openai("gpt-4o"),
  experimental_telemetry: {
    isEnabled: true,
    functionId: "my-awesome-function",
  },
});
```

## Configuration

By default this integration adds tracing support to all `ai` function callsites. If you need to disable span collection for a specific call, you can do so by setting `experimental_telemetry.isEnabled` to `false` in the first argument of the function call.

```javascript
const result = await generateText({
  model: openai("gpt-4o"),
  experimental_telemetry: { isEnabled: false },
});
```

If you set `experimental_telemetry.recordInputs` and `experimental_telemetry.recordOutputs` it will override the default behavior of collecting inputs and outputs for that function call.

```javascript
const result = await generateText({
  model: openai("gpt-4o"),
  experimental_telemetry: {
    isEnabled: true,
    recordInputs: true,
    recordOutputs: true,
  },
});
```

## Supported Versions

- `ai`: `>=3.0.0 <5`
