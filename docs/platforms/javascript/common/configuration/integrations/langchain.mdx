---
title: LangChain
description: "Adds instrumentation for LangChain."
supported:
  - javascript.node
  - javascript.aws-lambda
  - javascript.azure-functions
  - javascript.connect
  - javascript.express
  - javascript.fastify
  - javascript.gcp-functions
  - javascript.hapi
  - javascript.hono
  - javascript.koa
  - javascript.nestjs
  - javascript.electron
  - javascript.nextjs
  - javascript.nuxt
  - javascript.solidstart
  - javascript.sveltekit
  - javascript.react-router
  - javascript.remix
  - javascript.astro
  - javascript.bun
  - javascript.tanstackstart-react
  - javascript.cloudflare
  - javascript
  - javascript.react
  - javascript.angular
  - javascript.vue
  - javascript.svelte
  - javascript.solid
  - javascript.ember
  - javascript.gatsby
---

<PlatformSection notSupported={["javascript", "javascript.react", "javascript.angular", "javascript.vue", "javascript.svelte", "javascript.solid", "javascript.ember", "javascript.gatsby"]}>

## Server-Side Usage

_Import name: `Sentry.langChainIntegration`_

The `langChainIntegration` adds instrumentation for LangChain to capture spans by automatically wrapping LangChain operations and recording AI agent interactions with configurable input/output recording.

<Alert>

This integration is **enabled by default for Node.js-based platforms** and automatically captures spans for LangChain operations. It requires SDK version `10.22.0` or higher.

</Alert>

To customize what data is captured (such as inputs and outputs), see the [Options](#options) in the Configuration section.

### Supported Operations

By default, the integration automatically captures spans for LangChain operations including:

- **Chat model invocations** - Captures spans for chat model calls
- **LLM invocations** - Captures spans for LLM pipeline executions
- **Chain executions** - Captures spans for chain invocations
- **Tool executions** - Captures spans for tool calls

### Supported Runnables

The integration automatically instruments the following LangChain runnable methods:

- `invoke()` - Single execution
- `stream()` - Streaming execution
- `batch()` - Batch execution

### Supported Providers

The automatic instrumentation supports the following LangChain provider packages:

- `@langchain/anthropic`
- `@langchain/openai`
- `@langchain/google-genai`
- `@langchain/mistralai`
- `@langchain/google-vertexai`
- `@langchain/groq`

</PlatformSection>

<PlatformSection supported={["javascript", "javascript.react", "javascript.angular", "javascript.vue", "javascript.svelte", "javascript.solid", "javascript.ember", "javascript.gatsby", "javascript.nextjs", "javascript.nuxt", "javascript.solidstart", "javascript.sveltekit", "javascript.react-router", "javascript.remix", "javascript.astro", "javascript.tanstackstart-react", "javascript.electron", "javascript.cloudflare"]}>

## Browser-Side Usage

_Import name: `Sentry.createLangChainCallbackHandler`_

<PlatformSection supported={["javascript.cloudflare"]}>

<Alert>

For Cloudflare Workers edge runtime, manual instrumentation is required using `createLangChainCallbackHandler`.

</Alert>

</PlatformSection>

<PlatformSection supported={["javascript.nextjs"]}>

<Alert>

For Next.js applications using the Edge runtime, manual instrumentation is required using `createLangChainCallbackHandler`. This integration is automatically instrumented in the Node.js runtime.

</Alert>

</PlatformSection>

The `createLangChainCallbackHandler` helper adds instrumentation for LangChain to capture spans by creating a callback handler that wraps LangChain operations and records AI agent interactions with configurable input/output recording. You need to manually create and pass this callback handler to your LangChain operations. See example below:

```javascript
import * as Sentry from "@sentry/browser";
import { ChatAnthropic } from "@langchain/anthropic";

// Create a LangChain callback handler
const callbackHandler = Sentry.createLangChainCallbackHandler({
  recordInputs: true,
  recordOutputs: true,
});

// Use with chat models
const model = new ChatAnthropic({
  model: "claude-3-5-sonnet-20241022",
  apiKey: process.env.ANTHROPIC_API_KEY, // Warning: API key will be exposed in browser!
});

await model.invoke("Tell me a joke", {
  callbacks: [callbackHandler],
});
```

To customize what data is captured (such as inputs and outputs), see the [Options](#options) in the Configuration section.

</PlatformSection>

## Configuration

### Options

The following options control what data is captured from LangChain operations:

#### `recordInputs`

_Type: `boolean` (optional)_

Records inputs to LangChain operations (such as prompts and messages).

Defaults to `true` if `sendDefaultPii` is `true`.

#### `recordOutputs`

_Type: `boolean` (optional)_

Records outputs from LangChain operations (such as generated text and responses).

Defaults to `true` if `sendDefaultPii` is `true`.

**Usage**

<PlatformSection notSupported={["javascript", "javascript.react", "javascript.angular", "javascript.vue", "javascript.svelte", "javascript.solid", "javascript.ember", "javascript.gatsby"]}>

Automatic Instrumentation

```javascript
Sentry.init({
  dsn: "____PUBLIC_DSN____",
  tracesSampleRate: 1.0,
  integrations: [
    Sentry.langChainIntegration({
      // your options here
    }),
  ],
});
```

</PlatformSection>

<PlatformSection supported={["javascript", "javascript.react", "javascript.angular", "javascript.vue", "javascript.svelte", "javascript.solid", "javascript.ember", "javascript.gatsby", "javascript.nextjs", "javascript.nuxt", "javascript.solidstart", "javascript.sveltekit", "javascript.react-router", "javascript.remix", "javascript.astro", "javascript.tanstackstart-react", "javascript.electron", "javascript.cloudflare"]}>

Manual Instrumentation

```javascript
const callbackHandler = Sentry.createLangChainCallbackHandler({
  // your options here
});
```

</PlatformSection>

## Supported Versions

- `langchain`: `>=0.1.0 <2.0.0`
