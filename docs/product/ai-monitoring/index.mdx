---
title: "AI Monitoring"
sidebar_order: 62
description: "Sentry AI monitoring helps you understand your LLM calls."
---

<Include name="feature-stage-alpha.mdx" />

Sentry's AI Monitoring toolset helps you understand what's going on with your AI pipelines. It automatically collects information about prompts, tokens, and models from providers like OpenAI.

## Example AI Monitoring Use Cases

- Users are reporting issues with an AI workflow, and you want to see what the responses from the relevant large language models are.
- Workflows have been failing due to high token usage, and you want to see when token usage increased.
- Users report that AI workflows are taking longer than usual, and you want to understand what steps in a workflow are slowest.

To use AI Monitoring, you must have an existing Sentry account and project set up. If you don't have one, [create an account here](https://sentry.io/signup/).

![AI Monitoring User Interface](./img/details-view.png)


## Learn More About AI Monitoring

- [Getting started](/product/ai-monitoring/getting-started/)
