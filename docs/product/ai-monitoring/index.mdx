---
title: "AI Monitoring"
sidebar_order: 62
description: "Sentry AI monitoring helps you understand your LLM calls."
---

<Include name="feature-stage-alpha.mdx" />

Sentry's AI Monitoring tools help you understand what's going on with your AI pipelines. They automatically collect information about prompts, tokens, and models from providers like OpenAI.

## Example AI Monitoring Use Cases

- Users are reporting issues with an AI workflow, and you want to investigate responses from the relevant large language models.
- Workflows have been failing due to high token usage, and you want to understand the cause of the higher token usage.
- Users report that AI workflows are taking longer than usual, and you want to understand what steps in a workflow are slowest.

To use AI Monitoring, you must have an existing Sentry account and project set up. If you don't have one, [create an account here](https://sentry.io/signup/).

![AI Monitoring User Interface](./img/details-view.png)

- Learn how to [set up Sentry's AI Monitoring](/product/ai-monitoring/getting-started/).
