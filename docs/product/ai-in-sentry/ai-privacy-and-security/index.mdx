---
title: AI Privacy and Security
sidebar_order: 30
description: "Learn about how AI features in Sentry handle your data securely and protect your privacy."
---

Generative AI features in Sentry, including Seer, are designed with your privacy and security in mind. We take the following measures to ensure that your data is handled securely:

## Data Processing for Generative AI

We use the data listed below to provide insights, analysis, and solutions for your review. Your data will not be used to train any generative AI models by default and without your express consent, and AI-generated output from your data is shown only to you, not other customers.

Our generative AI features are powered by large language models (LLMs) hosted by subprocessors identified on our [subprocessor list](https://sentry.io/legal/subprocessors/). Our subprocessors are only permitted to use the data as directed by us.

The data used for these features includes:

- Error messages
- Stack traces
- Spans and traces
- Logs
- DOM interactions
- Profiles
- Relevant code from linked repositories

For EU-based customers, data is stored in the European Union.

You can learn more about our data privacy practices [here](/security-legal-pii/security/ai-ml-policy/#use-of-identifying-data-for-generative-ai-features).

## Privacy Guarantees

### No Training on Your Data

Your data will **not** be used to train any generative AI models by default and without your express consent, and AI-generated output from your data is shown only to you, not other customers.