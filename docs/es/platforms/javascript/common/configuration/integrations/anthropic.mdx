---
title: Anthropic
description: "Añade instrumentación para la API de Anthropic."
supported:
  - javascript.node
  - javascript.aws-lambda
  - javascript.azure-functions
  - javascript.connect
  - javascript.express
  - javascript.fastify
  - javascript.gcp-functions
  - javascript.hapi
  - javascript.hono
  - javascript.koa
  - javascript.nestjs
  - javascript.electron
  - javascript.nextjs
  - javascript.nuxt
  - javascript.solidstart
  - javascript.sveltekit
  - javascript.react-router
  - javascript.remix
  - javascript.astro
  - javascript.bun
  - javascript.tanstackstart-react
  - javascript.cloudflare
---

<Alert>

Esta integración funciona en los runtimes de Node.js, Cloudflare Workers y Vercel Edge Functions. Requiere la versión `10.12.0` o superior del SDK.

</Alert>

_Nombre de importación: `Sentry.anthropicAIIntegration`_

La `anthropicAIIntegration` añade instrumentación para `@anthropic-ai/sdk` para capturar spans envolviendo automáticamente las llamadas del cliente de Anthropic y registrando interacciones con LLM con registro de entrada/salida configurable.

<PlatformSection notSupported={["javascript.cloudflare", "javascript.nextjs"]}>
Está habilitada de forma predeterminada y capturará automáticamente spans de las llamadas a los métodos de la API de Anthropic. Puedes activar la captura de entradas y salidas configurando `recordInputs` y `recordOutputs` en la integración:

```javascript
Sentry.init({
  dsn: "____PUBLIC_DSN____",
  tracesSampleRate: 1.0,
  integrations: [
    Sentry.anthropicAIIntegration({
      recordInputs: true,
      recordOutputs: true,
    }),
  ],
});
```

</PlatformSection>

<PlatformSection supported={["javascript.cloudflare"]}>
Para Cloudflare Workers, debes instrumentar manualmente el cliente de Anthropic usando el helper `instrumentAnthropicAiClient`:

```javascript
import * as Sentry from "@sentry/cloudflare";
import Anthropic from "@anthropic-ai/sdk";

const anthropic = new Anthropic();
const client = Sentry.instrumentAnthropicAiClient(anthropic, {
  recordInputs: true,
  recordOutputs: true,
});

// Usa el cliente envuelto en lugar de la instancia original de anthropic
const response = await client.messages.create({
  model: "claude-3-5-sonnet-20241022",
  max_tokens: 1024,
  messages: [{ role: "user", content: "Hello!" }],
});
```

</PlatformSection>

<div id="options">
  ## Opciones
</div>

<div id="recordinputs">
  ### `recordInputs`
</div>

*Tipo: `boolean`*

Registra las entradas en las llamadas a métodos de la API de Anthropic (como indicaciones y mensajes).

De forma predeterminada, es `true` si `sendDefaultPii` es `true`.

```javascript
Sentry.init({
  integrations: [Sentry.anthropicAIIntegration({ recordInputs: true })],
});
```


<div id="recordoutputs">
  ### `recordOutputs`
</div>

*Tipo: `boolean`*

Registra las salidas de las llamadas a los métodos de la API de Anthropic (como el texto generado y las respuestas).

De forma predeterminada, es `true` si `sendDefaultPii` es `true`.

```javascript
Sentry.init({
  integrations: [Sentry.anthropicAIIntegration({ recordOutputs: true })],
});
```


<div id="configuration">
  ## Configuración
</div>

De forma predeterminada, esta integración añade compatibilidad con trazas a las llamadas a métodos de la API de Anthropic, incluidos:

- `messages.create()` - Crear mensajes con modelos Claude
- `messages.stream()` - Transmitir mensajes con modelos Claude
- `messages.countTokens()` - Contar tokens de mensajes
- `models.get()` - Obtener información del modelo
- `completions.create()` - Crear completions (legado)
- `models.retrieve()` - Recuperar detalles del modelo
- `beta.messages.create()` - API de mensajes en beta

La integración detectará automáticamente las solicitudes en streaming y las no streaming y las manejará adecuadamente.

<PlatformSection supported={['javascript.nextjs']}>

<div id="edge-runtime">
  ## Runtime de Edge
</div>

Esta integración se instrumenta automáticamente en el runtime de Node.js. Para aplicaciones de Next.js que usan el runtime de Edge, debes instrumentar manualmente el cliente de Anthropic:

```javascript
import * as Sentry from "@sentry/nextjs";
import Anthropic from "@anthropic-ai/sdk";

const anthropic = new Anthropic();
const client = Sentry.instrumentAnthropicAiClient(anthropic, {
  recordInputs: true,
  recordOutputs: true,
});

// Usa el cliente envuelto en lugar de la instancia original de anthropic
const response = await client.messages.create({
  model: "claude-3-5-sonnet-20241022",
  max_tokens: 1024,
  messages: [{ role: "user", content: "Hello!" }],
});
```

</PlatformSection>

<div id="supported-versions">
  ## Versiones admitidas
</div>

- `@anthropic-ai/sdk`: `>=0.19.2 <1.0.0`