---
title: Instrumentación de ejemplo
description: "Ejemplos de uso de métricas de spans para depurar problemas de rendimiento y supervisar el comportamiento de la aplicación en servicios de frontend y backend."
sidebar_order: 10
---

<Alert>

Estos ejemplos asumen que ya has <PlatformLink to="/tracing/">configurado el tracing</PlatformLink> en tu aplicación.

</Alert>

Esta guía ofrece ejemplos prácticos sobre cómo usar atributos y métricas de spans para resolver problemas comunes de observabilidad y depuración en toda tu pila de aplicaciones. Cada ejemplo muestra cómo instrumentar componentes tanto de frontend como de backend, y cómo funcionan en conjunto dentro de un trace distribuido para ofrecer visibilidad de extremo a extremo.

<div id="file-upload-and-processing-pipeline">
  ## Canal de carga y procesamiento de archivos
</div>

**Desafío:** Comprender los cuellos de botella y las fallas en operaciones de procesamiento de archivos de varios pasos, tanto en los componentes del cliente como en los del servidor.

**Solución:** Hacer un seguimiento de toda la canalización de procesamiento de archivos con métricas detalladas en cada etapa, desde la preparación de la carga en el cliente hasta el procesamiento en el servidor.

**Instrumentación del frontend:**

```javascript
// Manejo de carga de archivos del lado del cliente
Sentry.startSpan(
  {
    name: "Carga de archivos del lado del cliente",
    op: "file.upload.client",
    attributes: {
      // Detalles estáticos disponibles al inicio
      "file.size_bytes": 15728640, // 15 MB
      "file.type": "image/jpeg",
      "file.name": "user-profile.jpg",
      "client.compression_applied": true,
    },
  },
  async (span) => {
    try {
      // Iniciar el proceso de carga
      const uploader = new FileUploader(file);

      // Actualizar el progreso a medida que avanza la carga
      uploader.on("progress", (progressEvent) => {
        span.setAttribute("upload.percent_complete", progressEvent.percent);
        span.setAttribute("upload.bytes_transferred", progressEvent.loaded);
      });

      uploader.on("retry", (retryCount) => {
        span.setAttribute("upload.retry_count", retryCount);
      });

      const result = await uploader.start();

      // Definir atributos finales tras la finalización
      span.setAttribute("upload.total_time_ms", result.totalTime);
      span.setAttribute("upload.success", true);
      span.setAttribute("upload.server_file_id", result.fileId);

      return result;
    } catch (error) {
      // Registrar información del fallo
      span.setAttribute("upload.success", false);
      Sentry.captureException(error);
    }
  }
);
```

**Instrumentación del backend:**

```javascript
// Procesamiento del lado del servidor
Sentry.startSpan(
  {
    name: "Server File Processing",
    op: "file.process.server",
    attributes: {
      // Pasos de procesamiento del servidor
      "processing.steps_completed": [
        "virus_scan",
        "resize",
        "compress",
        "metadata",
      ],

      // Operaciones de almacenamiento
      "storage.provider": "s3",
      "storage.region": "us-west-2",
      "storage.upload_time_ms": 850,

      // Configuración de CDN
      "cdn.provider": "cloudfront",
      "cdn.propagation_ms": 1500,
    },
  },
  async () => {
    // Implementación del procesamiento del lado del servidor
  }
);
```

**Cómo funciona el trace en conjunto:**
El span del frontend inicia el trace y gestiona el proceso de carga de archivos. Propaga el contexto del trace al backend a través de los encabezados de la solicitud de carga. El span del backend continúa el trace, procesa el archivo y lo almacena. Esto ofrece una visión completa del recorrido del archivo desde el cliente hasta el CDN, lo que te permite:

* Identificar cuellos de botella en cualquier etapa (preparación en el cliente, carga, procesamiento en el servidor, propagación en el CDN)
* Medir tiempos de procesamiento de extremo a extremo y tasas de éxito
* Supervisar el uso de recursos en toda la pila
* Correlacionar problemas de carga en el cliente con errores de procesamiento en el servidor


<div id="llm-integration-monitoring">
  ## Monitoreo de la integración con LLM
</div>

**Desafío:** Gestionar el coste (uso de tokens) y el rendimiento de las integraciones con LLM en los componentes de frontend y backend.

**Solución:** Seguimiento de todo el flujo de interacción con el LLM, desde la entrada del usuario hasta la representación de la respuesta.

**Instrumentación del frontend:**

```javascript
// Manejo de interacción con LLM del lado del cliente
Sentry.startSpan(
  {
    name: "Interacción con Cliente LLM",
    op: "gen_ai.generate_text",
    attributes: {
      // Métricas iniciales disponibles al momento de la solicitud
      "input.char_count": 280,
      "input.language": "en",
      "input.type": "question",
    },
  },
  async (span) => {
    const startTime = performance.now();

    // Iniciar respuesta en streaming desde la API del LLM
    const stream = await llmClient.createCompletion({
      prompt: userInput,
      stream: true,
    });

    // Registrar tiempo hasta el primer token al recibirlo
    let firstTokenReceived = false;
    let tokensReceived = 0;

    for await (const chunk of stream) {
      tokensReceived++;

      // Registrar tiempo hasta el primer token
      if (!firstTokenReceived && chunk.content) {
        firstTokenReceived = true;
        const timeToFirstToken = performance.now() - startTime;

        span.setAttribute("ui.time_to_first_token_ms", timeToFirstToken);
      }

      // Procesar y renderizar el fragmento
      renderChunkToUI(chunk);
    }

    // Registrar métricas finales al completarse el stream
    const totalRequestTime = performance.now() - startTime;

    span.setAttribute("ui.total_request_time_ms", totalRequestTime);
    span.setAttribute("stream.rendering_mode", "markdown");
    span.setAttribute("stream.tokens_received", tokensReceived);
  }
);
```

**Instrumentación del back‑end:**

```javascript
// Procesamiento de LLM en el lado del servidor
Sentry.startSpan(
  {
    name: "Procesamiento de la API de LLM",
    op: "gen_ai.generate_text",
    attributes: {
      // Configuración del modelo: conocida desde el inicio
      "llm.model": "claude-3-5-sonnet-20241022",
      "llm.temperature": 0.5,
      "llm.max_tokens": 4096,
    },
  },
  async (span) => {
    const startTime = Date.now();

    try {
      // Comprobar los límites de uso antes de procesar
      const rateLimits = await getRateLimits();
      span.setAttribute("llm.rate_limit_remaining", rateLimits.remaining);

      // Realizar la llamada a la API del proveedor de LLM
      const response = await llmProvider.generateCompletion({
        model: "claude-3-5-sonnet-20241022",
        prompt: preparedPrompt,
        temperature: 0.5,
        max_tokens: 4096,
      });

      // Registrar el uso de tokens y las métricas de rendimiento
      span.setAttribute("llm.prompt_tokens", response.usage.prompt_tokens);
      span.setAttribute(
        "llm.completion_tokens",
        response.usage.completion_tokens
      );
      span.setAttribute("llm.total_tokens", response.usage.total_tokens);
      span.setAttribute("llm.api_latency_ms", Date.now() - startTime);

      // Calcular y registrar el costo según el uso de tokens
      const cost = calculateCost(
        response.usage.prompt_tokens,
        response.usage.completion_tokens,
        "claude-3-5-sonnet-20241022"
      );
      span.setAttribute("llm.cost_usd", cost);

      return response;
    } catch (error) {
      // Registrar los detalles del error
      span.setAttribute("error", true);
      Sentry.captureException(error);
    }
  }
);
```

**Cómo funciona el trace en conjunto:**
El span del frontend captura la interacción del usuario y el rendimiento del renderizado de la UI, mientras que el span del backend registra la interacción real con la API del LLM. El trace distribuido muestra el flujo completo desde la entrada del usuario hasta la respuesta renderizada, lo que te permite:

* Analizar los tiempos de respuesta de extremo a extremo y la experiencia del usuario
* Rastrear costos y patrones de uso de tokens
* Optimizar el rendimiento del streaming y el renderizado de la UI
* Supervisar los límites de tasa y los tiempos en cola
* Correlacionar las entradas del usuario con el rendimiento del modelo


<div id="e-commerce-transaction-flow">
  ## Flujo de transacciones de comercio electrónico
</div>

**Desafío:** Entender el flujo de compra completo e identificar problemas que afectan a los ingresos en toda la pila.

**Solución:** Hacer un seguimiento de todo el proceso de compra, desde la interacción con el carrito hasta el procesamiento del pedido.

**Instrumentación del front-end:**

```javascript
// Proceso de checkout del lado del cliente
Sentry.startSpan(
  {
    name: "Flujo de UI de Checkout",
    op: "commerce.checkout.client",
    attributes: {
      // Métricas de interacción del carrito
      "cart.items_added": 3,
      "cart.items_removed": 0,
      "cart.update_count": 2,

      // Seguimiento de interacción del usuario
      "ui.form_completion_time_ms": 45000,
      "ui.payment_method_changes": 1,
      "ui.address_validation_retries": 0,
    },
  },
  async () => {
    // Implementación del checkout del lado del cliente
  }
);
```

**Instrumentación del backend:**

```javascript
// Procesamiento de pedidos en el servidor
Sentry.startSpan(
  {
    name: "Procesamiento de pedidos",
    op: "commerce.order.server",
    attributes: {
      // Detalles del pedido
      "order.id": "ord_123456789",
      "order.total_amount": 159.99,
      "order.currency": "USD",
      "order.items": ["SKU123", "SKU456", "SKU789"],

      // Procesamiento del pago
      "payment.provider": "stripe",
      "payment.method": "credit_card",
      "payment.processing_time_ms": 1200,

      // Comprobaciones de inventario
      "inventory.all_available": true,

      // Cumplimentación
      "fulfillment.warehouse": "WEST-01",
      "fulfillment.shipping_method": "express",
      "fulfillment.estimated_delivery": "2024-03-20",
    },
  },
  async () => {
    // Procesamiento de pedidos en el servidor
  }
);
```

**Cómo funciona el trace en conjunto:**
El span de frontend registra la experiencia de compra del usuario, mientras que el span de backend gestiona el procesamiento y la preparación del pedido. El trace distribuido ofrece visibilidad de todo el flujo de compra, lo que te permite:

* Analizar el rendimiento del embudo de compra y los puntos de abandono
* Registrar las tasas de éxito y los tiempos del procesamiento de pagos
* Supervisar el impacto de la disponibilidad de inventario en las conversiones
* Medir los tiempos de finalización del pedido de extremo a extremo
* Identificar puntos de fricción en la experiencia del usuario
