---
title: Celery
redirect_from:
  - /clients/python/integrations/celery/
  - /platforms/python/celery/
description: "Learn about using Sentry with Celery."
---

The Celery integration adds support for the [Celery Task Queue System](https://docs.celeryq.dev/).

Just add `CeleryIntegration()` to your `integrations` list:

<SignInNote />

```python
import sentry_sdk
from sentry_sdk.integrations.celery import CeleryIntegration

sentry_sdk.init(
    dsn='___PUBLIC_DSN___',
    integrations=[
        CeleryIntegration(),
    ],

    # Set traces_sample_rate to 1.0 to capture 100%
    # of transactions for performance monitoring.
    # We recommend adjusting this value in production,
    traces_sample_rate=1.0,
)
```

Additionally, the Sentry Python SDK will set the transaction on the event to the task name, and it will improve the grouping for global Celery errors such as timeouts.

The integration will automatically report errors from all celery jobs.

Generally, make sure that the **call to `init` is loaded on worker startup**, and not only in the module where your tasks are defined. Otherwise, the initialization happens too late and events might end up not being reported.

## Standalone Setup

If you're using Celery standalone, there are two ways to set this up:

- Initializing the SDK in the configuration file loaded with Celery's `--config` parameter
- Initializing the SDK by hooking it to either the [`celeryd_init`](https://docs.celeryq.dev/en/stable/userguide/signals.html?#celeryd-init) or [`worker_init`](https://docs.celeryq.dev/en/stable/userguide/signals.html?#worker-init) signals

  ```python
  import sentry_sdk
  from celery import Celery, signals

  app = Celery("myapp")

  #@signals.worker_init.connect
  @signals.celeryd_init.connect
  def init_sentry(**_kwargs):
      sentry_sdk.init(dsn="...")
  ```

## Setup With Django

If you're using Celery with Django in a conventional setup, have already initialized the SDK in [your `settings.py` file](/platforms/python/guides/django/#configure), and have Celery using the same settings with [`config_from_object`](https://docs.celeryq.dev/en/stable/django/first-steps-with-django.html), you don't need to initialize the SDK separately for Celery.

## Verify

To verify if your SDK is initialized on worker start, you can pass `debug=True` to see extra output when the SDK is initialized. If the output appears during worker startup and not only after a task has started, then it's working properly.

<Alert level="info" title="Note on distributed tracing">

Sentry uses custom message headers for distributed tracing. For Celery versions 4.x, with [message protocol of version 1](https://docs.celeryq.dev/en/stable/internals/protocol.html#version-1), this functionality is broken, and Celery fails to propagate custom headers to the worker. Protocol version 2, which is the default since Celery version 4.0, is not affected.

The fix for the custom headers propagation issue was introduced to Celery project ([PR](https://github.com/celery/celery/pull/6374)) starting with version 5.0.1. However, the fix was not backported to versions 4.x.

</Alert>

## Options

To set options on `CeleryIntegration` to change its behavior, add it explicitly to your `sentry_sdk.init()`:

```python
import sentry_sdk
from sentry_sdk.integrations.celery import CeleryIntegration

sentry_sdk.init(
    dsn="___PUBLIC_DSN___",
    # ...
    integrations=[
        CeleryIntegration(
            monitor_beat_tasks=True,
            exclude_beat_tasks=["unimportant-task", "payment-check-.*"],
        ),
    ],
)
```

You can pass the following keyword arguments to `CeleryIntegration()`:

- `propagate_traces`

  Propagate Sentry tracing information to the Celery task. This makes it possible to link errors in Celery tasks to the function that triggered the Celery task.

  If this is set to `False`:

  - errors in Celery tasks can't be matched to the triggering function.
  - your Celery tasks will start a new trace and not be connected to the trace in the calling function

  The default is `True`.

- `monitor_beat_tasks`:

  Turn auto-instrumentation on or off for Celery Beat tasks using Sentry Crons.

  See <PlatformLink to="/crons/#celery-beat-auto-discovery">Celery Beat Auto Discovery</PlatformLink> to learn more.

  The default is `False`.

- `exclude_beat_tasks`:

  A list of Celery Beat tasks that should be excluded from auto-instrumentation using Sentry Crons. Only applied if `monitor_beat_tasks` is set to `True`.

  The list can contain strings with the names of tasks in the Celery Beat schedule to be excluded. It can also include regular expressions to match multiple tasks. For example, if you include `"payment-check-.*"` every task starting with `payment-check-` will be excluded from auto-instrumentation.

  See <PlatformLink to="/crons/#celery-beat-auto-discovery">Celery Beat Auto Discovery</PlatformLink> to learn more.

  The default is `None`.

## Distributed Traces

Distributes tracing means, that the code running in your Celery tasks will be part of the trace that was started in the code that started your Celery task.

You can disable distributing the tracing information into your Celery tasks globally with the `propagate_traces` parameter documented above. If you set `propagate_traces` to `False` all Celery tasks will start their own new trace.

If you want to have more fine grained control over trace distribution, you can overide the `propagate_traces` option by passing the `sentry-propagate-traces` header when starting the Celery task:

```python
import sentry_sdk

# Enable global distributed traces (this is the default, just to be explicit.)
sentry_sdk.init(
    dsn="___PUBLIC_DSN___",
    integrations=[
        CeleryIntegration(propagate_traces=True),
    ],
)

# This will propagate the trace:
my_task_a.delay("some parameter")

# This will propagate the trace:
my_task_b.apply_async(args=("some_parameter", ))

# This will NOT propagate the trace. (The task will start its own trace):
my_task_b.apply_async(args=("some_parameter", ), headers={"sentry-propagate-traces": False})

# Note: overriding the tracing behaviour using `task_x.delay()` is not possible.
```
